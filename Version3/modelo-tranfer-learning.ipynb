{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:09:38.290287Z","iopub.status.busy":"2023-03-31T01:09:38.287593Z","iopub.status.idle":"2023-03-31T01:09:39.960683Z","shell.execute_reply":"2023-03-31T01:09:39.959726Z","shell.execute_reply.started":"2023-03-31T01:09:38.290209Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","import pandas as pd\n","from tqdm import tqdm\n","import cv2\n","from PIL import Image\n","from skimage import exposure\n","from skimage.transform import resize\n","import scipy\n","import time\n","from statistics import mean\n","import tensorflow as tf\n","import keras as ke\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.layers import Input\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-03-31T01:09:45.080211Z","iopub.status.busy":"2023-03-31T01:09:45.079057Z","iopub.status.idle":"2023-03-31T01:09:45.085202Z","shell.execute_reply":"2023-03-31T01:09:45.084213Z","shell.execute_reply.started":"2023-03-31T01:09:45.080131Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:09:52.108086Z","iopub.status.busy":"2023-03-31T01:09:52.107639Z","iopub.status.idle":"2023-03-31T01:09:52.191697Z","shell.execute_reply":"2023-03-31T01:09:52.190337Z","shell.execute_reply.started":"2023-03-31T01:09:52.108048Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imageId</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>89.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>72.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>25.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>68.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>37.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10697</th>\n","      <td>10697</td>\n","      <td>79.0</td>\n","    </tr>\n","    <tr>\n","      <th>10698</th>\n","      <td>10698</td>\n","      <td>67.0</td>\n","    </tr>\n","    <tr>\n","      <th>10699</th>\n","      <td>10699</td>\n","      <td>66.0</td>\n","    </tr>\n","    <tr>\n","      <th>10700</th>\n","      <td>10700</td>\n","      <td>78.0</td>\n","    </tr>\n","    <tr>\n","      <th>10701</th>\n","      <td>10701</td>\n","      <td>74.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10702 rows × 2 columns</p>\n","</div>"],"text/plain":["       imageId   age\n","0            0  89.0\n","1            1  72.0\n","2            2  25.0\n","3            3  68.0\n","4            4  37.0\n","...        ...   ...\n","10697    10697  79.0\n","10698    10698  67.0\n","10699    10699  66.0\n","10700    10700  78.0\n","10701    10701  74.0\n","\n","[10702 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["Tabela_treino = pd.read_csv('/kaggle/input/spr-x-ray-age/train_age.csv',sep = ',',engine = 'python')\n","display(Tabela_treino)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:09:57.369181Z","iopub.status.busy":"2023-03-31T01:09:57.368722Z","iopub.status.idle":"2023-03-31T01:19:18.552011Z","shell.execute_reply":"2023-03-31T01:19:18.550625Z","shell.execute_reply.started":"2023-03-31T01:09:57.369122Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10702/10702 [09:21<00:00, 19.07it/s]\n"]}],"source":["nlin = np.shape(Tabela_treino)[0]   #numero de linhas da minha tabela do excel\n","hhh = []\n","tamy = []\n","\n","for i in tqdm(range(0,nlin)):\n","    imageID = Tabela_treino['imageId'].iloc[i]      #pega o valor do imageID de cada linha \n","    file_path = (\"/kaggle/input/spr-x-ray-age/kaggle/kaggle/train/\"  + str(imageID).zfill(6) + \".png\")\n","    img = cv2.imread(file_path) #aplica o numero do imageID pra buscar a imagem no diretório com o mesmo numero\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = cv2.merge((img,img,img))\n","    img = cv2.resize(img, (200,200), interpolation = cv2.INTER_AREA)\n","    img = np.array(img)/255\n","    hhh.append(img)\n","    tamy.append(Tabela_treino['age'].iloc[i])\n","tamy = np.array(tamy)\n","    "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:20:42.261916Z","iopub.status.busy":"2023-03-31T01:20:42.260724Z","iopub.status.idle":"2023-03-31T01:20:42.272643Z","shell.execute_reply":"2023-03-31T01:20:42.271196Z","shell.execute_reply.started":"2023-03-31T01:20:42.261864Z"},"trusted":true},"outputs":[],"source":["X_treino, X_val, Y_treino, Y_val = train_test_split(hhh, tamy, test_size=0.2, random_state=50,shuffle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-03-30T22:18:03.163107Z","iopub.status.busy":"2023-03-30T22:18:03.162309Z","iopub.status.idle":"2023-03-30T22:18:09.661725Z","shell.execute_reply":"2023-03-30T22:18:09.660217Z","shell.execute_reply.started":"2023-03-30T22:18:03.163062Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 []\n","(8561, 200, 200, 3) (2141, 200, 200, 3) (8561,) (2141,)\n"]}],"source":["tamy = 0 #list(Y_all).clear()\n","hhh.clear()\n","\n","print(tamy, hhh)\n","print(np.shape(X_treino), np.shape(X_val), np.shape(Y_treino), np.shape(Y_val))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Sem Kfold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from keras.applications import EfficientNetB2\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.optimizers import Adam\n","\n","start_time = time.time()\n","\n","np.random.RandomState(1) # Fixar o pseudo-random generator do numpy\n","tf.random.set_seed(1) # Fixar o pseudo-random generator do tensorflow\n","# criando a base da EfficientNet pré-treinada\n","base_model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n","\n","# adicionando camadas de classificação no topo da base_model\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu')(x)\n","predictions = Dense(1)(x)\n","\n","# definindo o modelo final\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# congelando as camadas da base_model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","opt = ke.optimizers.Adam( learning_rate=0.01,\n","beta_1=0.9,\n","beta_2=0.999,\n","epsilon=1e-07,\n","amsgrad=False)\n","#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n","model.compile(optimizer= opt, loss='mse',metrics=['mae'])  # Compilando o modelo\n","\n","history = model.fit(np.array(X_treino), Y_treino,batch_size = 100, epochs = 50, validation_data = (np.array(X_val), Y_val))\n","    \n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(history.history[\"loss\"], label=\"treino\")\n","plt.plot(history.history[\"val_loss\"], label=\"validacao\")\n","plt.xlabel(\"epocas\")\n","plt.ylabel(\"Loss\")\n","plt.ylim( bottom = 0, top = 0.5)\n","plt.legend(loc='upper right');\n","plt.subplot(1,2,2)\n","plt.plot(history.history[\"accuracy\"], label=\"treino\")\n","plt.plot(history.history[\"val_accuracy\"], label=\"validacao\")\n","plt.xlabel(\"epocas\")\n","plt.ylabel(\"Acuracia\")\n","plt.ylim( bottom = 0.9, top = 1)\n","plt.legend(loc='lower right');"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#salvar o modelo do melhor fold\n","model.save('modelclass(female)sem_kfold_tranfer_learning.h5')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Com Kfold"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-31T01:21:12.720349Z","iopub.status.busy":"2023-03-31T01:21:12.719894Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n","31790344/31790344 [==============================] - 2s 0us/step\n","------------------------------------------------------------------------\n","Treinamento para o fold 1 ...\n"]}],"source":["from keras.applications import EfficientNetB2\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.optimizers import Adam\n","\n","start_time = time.time()\n","\n","#iniciando as listas\n","mae_por_fold = []\n","loss_por_fold = []\n","all_models=[]\n","all_loss=[]\n","all_mae=[]\n","all_vloss=[]\n","all_vmae=[]\n","\n","#Dados de entrada\n","inputs = np.array(hhh)\n","targets = tamy\n","\n","# escolher o numero de folds\n","num_folds = 5\n","\n","# Validação cruzada\n","kfold = KFold(n_splits=num_folds, shuffle=True)\n","fold_no = 1\n","for train, test in kfold.split(inputs, targets):\n","\n","    # criando a base da ResNet50 pré-treinada\n","    base_model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n","\n","    # adicionando camadas de classificação no topo da base_model\n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(256, activation='relu')(x)\n","    predictions = Dense(1)(x)\n","\n","    # definindo o modelo final\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","\n","    # congelando as camadas da base_model\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","\n","    opt = ke.optimizers.Adam( learning_rate=0.01,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=1e-07,\n","    amsgrad=False)\n","    #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n","    model.compile(optimizer= opt, loss='mse',metrics=['mae'])  # Compilando o modelo\n","    \n","\n","    print('------------------------------------------------------------------------')\n","    print(f'Treinamento para o fold {fold_no} ...')\n","    \n","    # Fit data to model\n","    history = model.fit(inputs[train], targets[train],\n","              batch_size=100,\n","              #callbacks=[callback],\n","              epochs=100,\n","              validation_data=(inputs[test], targets[test]))\n","\n","  \n","    mse, mae =  model.evaluate(inputs[test], targets[test], verbose=0)\n","    print(f'Score para o fold {fold_no}: {model.metrics_names[0]} de {mse}; {model.metrics_names[1]} de {mae}')\n","    mae_por_fold.append(mae) # aqui estamos criando uma lista com as accs dos 5 folds\n","    loss_por_fold.append(mse)    # aqui estamos criando uma lista com as loss dos 5 folds\n","    \n","   # Increase fold number\n","    fold_no = fold_no + 1\n","    \n","    \n","    all_models.append(model)\n","    \n","    all_vloss.append(history.history[\"val_loss\"])\n","    all_vmae.append(history.history[\"val_mae\"])\n","    all_loss.append(history.history[\"loss\"])\n","    all_mae.append(history.history[\"mae\"])\n","    \n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#salvar o modelo do melhor fold\n","model.save('model_kfold_tranfer_learning.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","\n","# Salvar todas as variáveis em um arquivo pickle\n","with open(\"all_variables.pkl\", \"wb\") as f:\n","    pickle.dump([all_models, all_vloss, all_vacc, all_loss, all_acc, acc_por_fold,loss_por_fold], f)\n","\n","# # Carregar as variáveis a partir do arquivo pickle\n","# with open(\"all_variables.pkl\", \"rb\") as f:\n","#     all_models, all_vloss, all_vacc, all_loss, all_acc, acc_por_fold,loss_por_fold = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dados de Saida\n","print('------------------------------------------------------------------------')\n","print('Scores para cada um dos folds:')\n","\n","for i in range(0, len(acc_por_fold)):\n","        print('------------------------------------------------------------------------')\n","        print(f'> Fold {i+1} - Loss: {loss_por_fold[i]} - acc: {acc_por_fold[i]}')\n","    \n","print('------------------------------------------------------------------------')\n","print('Média dos scores para todos os folds:')\n","print(f'> acc: {np.mean(acc_por_fold)} (+- {np.std(acc_por_fold)})')\n","print(f'> Loss: {np.mean(loss_por_fold)}(+- {np.std(acc_por_fold)})')\n","print('------------------------------------------------------------------------')\n","print(f'> Tamanho do conjunto de treinamento e conjunto de teste por fold: {(len(train), len(test))}')\n","\n","\n","\n","fig, axs = plt.subplots(2, 2, figsize=(15,10))\n","for i in range(num_folds):\n","    axs[0, 0].plot(all_loss[i], label=\"fold\"+str(i+1))\n","    axs[0, 0].set_title('loss (treino) por fold')\n","    axs[0, 0].legend(loc='upper right')\n","    axs[0, 0].set_xlabel('Epochs')\n","    axs[0, 0].set_ylabel('Loss')\n","    axs[0, 0].grid()\n","\n","    axs[0, 1].plot(all_vloss[i], label=\"fold\"+str(i+1))\n","    axs[0, 1].set_title('loss (validacao) por fold')\n","    axs[0, 1].legend(loc='upper right')\n","    axs[0, 1].set_xlabel('Epochs')\n","    axs[0, 1].set_ylabel('Validação Loss')\n","    axs[0, 1].grid()\n","\n","    axs[1, 0].plot(all_acc[i], label=\"fold\"+str(i+1))\n","    axs[1, 0].set_title('acc (treino) por fold')\n","    axs[1, 0].legend(loc='lower right')\n","    axs[1, 0].set_xlabel('Epochs')\n","    axs[1, 0].set_ylabel('acc')\n","    axs[1, 0].grid()\n","\n","    axs[1, 1].plot(all_vacc[i], label=\"fold\"+str(i+1))\n","    axs[1, 1].set_title('acc (validacao) por fold')\n","    axs[1, 1].legend(loc='lower right')\n","    axs[1, 1].set_xlabel('Epochs')\n","    axs[1, 1].set_ylabel('Validação acc')\n","    axs[1, 1].grid()\n","\n","# plt.savefig('img0.png', bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def smooth_curve(points, factor=0.7):\n","    smoothed_points = []\n","    for point in points:\n","        if smoothed_points:\n","            previous = smoothed_points[-1]\n","            smoothed_points.append(previous * factor + point * (1 - factor))\n","        else:\n","            smoothed_points.append(point)\n","    return smoothed_points\n","\n","smooth_vacc_history = []\n","smooth_acc_history = []\n","smooth_vloss_history = []\n","smooth_loss_history = []\n","\n","for i in range(0,num_folds):\n","    Vacc = smooth_curve(all_vacc[i][50:])\n","    acc = smooth_curve(all_acc[i][50:])\n","    VLoss = smooth_curve(all_vloss[i][50:])\n","    Loss = smooth_curve(all_loss[i][50:])\n","    \n","    smooth_vacc_history.append(Vacc)\n","    smooth_acc_history.append(acc)\n","    smooth_vloss_history.append(VLoss)\n","    smooth_loss_history.append(Loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('------------------------------------------------------------------------')\n","print('Média dos scores para todos os folds:')\n","print(f'> acc: {np.mean(acc_por_fold)} (+- {np.std(acc_por_fold)})')\n","#print(f'> Loss: {np.mean(loss_por_fold)}(+- {np.std(acc_por_fold)})')\n","print('------------------------------------------------------------------------')\n","print(f'> Tamanho do conjunto de treinamento e validação por fold: {(len(train), len(test))}')\n","\n","\n","fig, axs = plt.subplots(2, 2, figsize=(15,10))\n","for i in range(num_folds):\n","    axs[0, 0].plot(smooth_loss_history[i],label=\"fold\"+str(i+1))\n","    axs[0, 0].set_title('loss (treino) por fold')\n","    axs[0, 0].legend(loc='upper right')\n","    axs[0, 0].set_xlabel('Epochs')\n","    axs[0, 0].set_ylabel('Loss')\n","    axs[0, 0].grid()\n","    axs[0, 1].plot(smooth_vloss_history[i],label=\"fold\"+str(i+1))\n","    axs[0, 1].set_title('loss (validacao) por fold')\n","    axs[0, 1].legend(loc='upper right')\n","    axs[0, 1].set_xlabel('Epochs')\n","    axs[0, 1].set_ylabel('Validação Loss')\n","    axs[0, 1].grid()\n","    axs[1, 0].plot(smooth_acc_history[i],label=\"fold\"+str(i+1))\n","    axs[1, 0].set_title('acc (dados de treino) por fold')\n","    axs[1, 0].legend(loc='lower right')\n","    axs[1, 0].set_xlabel('Epochs')\n","    axs[1, 0].set_ylabel('acc')\n","    axs[1, 0].grid()\n","    axs[1, 1].plot(smooth_vacc_history[i],label=\"fold\"+str(i+1))\n","    axs[1, 1].set_title('acc (dados de validacao) por fold')\n","    axs[1, 1].legend(loc='lower right')\n","    axs[1, 1].set_xlabel('Epochs')\n","    axs[1, 1].set_ylabel('Validação acc')\n","    axs[1, 1].grid()      \n","# plt.savefig('img1.png', bbox_inches='tight');"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
